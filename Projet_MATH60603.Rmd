---
# title: 'Projet '
# author: "Jean Guirguis (11290393) et David Gascon (xxxxxxx)"
# date: "xx/12/2020"
# output:
#   pdf_document:
#     toc: true
#   word_document: default
#   html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# Librairies
library(gridExtra)
library(grid)
library(ggplot2)
library(lattice)
```

######
Note : 

baggin + svm  + regression linéaire

équilibrer VS non équilibré (3 méthode)



######



# Introduction : présentation des objectifs de l’étude

L'objectif de cette étude est de faire une prédiction sur le désbonnemennt d'un client pour un service de télécommunication. Cette simulation a été fait à partir d'une base de données présent sur kaggle à l'adresse suivante : https://www.kaggle.com/mnassrib/telecom-churn-datasets?select=churn-bigml-80.csv. L'analyse a été effectué sur les client d'Orange Telecom aux États-Unis et plusieurs variables on été analysés tels que lieu géographique, le type de plan que le client possède, le nombre de minutes utilisé pour des appels durant le jour et le soir, etc. 

Ce rapport contient en premier lieu, une présentation détaillés de notre méthode d'analyse. Cette section contiendra d'abord une exploration détaillés des données possédés, un traitement et un nettoyage préparatoire des données. Puis, plusieurs méthode et stratégie de prédiction seront testés afin de déterminer le modèle le mieux adapté à notre échantillion d'utilisateurs. 

Une fois le modèle choisi, la deuxième section du rapport présentera les résultats du modèle de prédiction.  

... ... ... ... ... 







# Méthode : présentation du design de l’étude et des différents scénarios utilisés. Présentation de la méthode d’analyse en général.

## Exploration des données

### Présentation des varaibles
### Traitement et nettoyage préparatoire des données  










###################################


# Exploration des données

```{r}
# Importation des données

train0=read.csv("data/churn-bigml-80.csv")
nb_ligne_train = nrow(train0)
test0=read.csv("data/churn-bigml-20.csv")
mydata = rbind(train0,test0)
id.train=c(1:nrow(train0))
id.test=c((nrow(train0)+1):(nrow(mydata)))



train= mydata[id.train,]
test = mydata[id.test,]
attributes(test)$row.names = attributes(test0)$row.names
identical(train,train0)
identical(test,test0)
all.equal(train,train0)
all.equal(test,test0)
```


```{r}
summary(train)
```
## Réencodage des variables "State", "International.plan" et "Voice.mail.plan" en facteur. La variable d'intérêt est réencodée en variable logique, à savoir que les valeurs "vrai" sont codées "1" et les valeurs "faux" sont codées en 0
```{r}
#transformation des variables "character" en "facteur"

mydata$State=as.factor(mydata$State)
mydata$International.plan=as.factor(mydata$International.plan)
mydata$Voice.mail.plan=as.factor(mydata$Voice.mail.plan)

#transformation variable d'intérêt en variable logique
mydata$Churn=as.logical(mydata$Churn)


train= mydata[id.train,]
test = mydata[id.test,]
attributes(test)$row.names = attributes(test0)$row.names
```
## Étude descriptive des données

```{r}
# fonction 
analyse_table = function (nom,variable,nb_donne)
{
  table_temporaire= table(variable)
  table_temporaire = as.data.frame(table_temporaire)
  table_temporaire = data.frame(table_temporaire,pourcentage=round(table_temporaire[2]/nb_donne*100, digit =2))
  names(table_temporaire)[3] = "% Freq"
  names(table_temporaire)[1] = nom
  #table_temporaire = head(table_temporaire[order(-table_temporaire[3]),],3)
  table_temporaire = table_temporaire[order(-table_temporaire[3]),]
  return(table_temporaire)
}

analyse_table('State',train$State,nrow(train))
analyse_table('International.plan',train$International.plan,nrow(train))
analyse_table('Voice.mail.plan',train$Voice.mail.plan,nrow(train))
analyse_table('Churn',train$Churn,nrow(train))
analyse_table('Area.code',train$Area.code,nrow(train))
```


```{r}

par(mfrow=c(2,4))
for (i in 1:length(colnames(train)))
{
  if (i != 1 & i !=3  & i != 4 & i != 5 & i !=length(colnames(train)))
  {
    hist(train[,i], main = (colnames(train)[i] ),xlab = element_blank(),col = i+1)
    Axis(side=1, labels=FALSE)
    #plot(train[,i], main = (colnames(train)[i] ))
  }
}
```


REMARQUE : Si on conserve les varialbes Customer.service.calls et total.intl,calls en variables numériques, il faudra surement prendre le log de ces variables car elles sont asymetriques à droite.!!

## Analyse descriptive des données 

```{r}
summary(train)
```

Le dataset d'entraînement ne contient aucune valeur manquante. il y a 15 variables continues, 3 variables catégorielles, et une variables binaires. (a faire avec cours chapitre 9 .... is na .... )

```{r}
round(mean(train$Churn),digits=2)
```
Le pourcentage de clients ayant quittés la compagnie est de 15%.\

```{r,include=FALSE}
library("plotly")
library("corrplot")
```

```{r}
corrplot(cor(train[,c(2,3,6:19)]), method = "color", addCoef.col="grey", order = "AOE",tl.cex=0.75,tl.col="black",number.cex = 0.5)
```
Les varaibles du dataset sont faiblement corrélées à l'exception des variables indiquant le nombre de muinutes consommés et les frais chargés associés, comme les varaibles : "Total.night charge" et "Total.night.minutes". Comme ces variables ont une corrélation parfaites, nous décidons de supprimer du dataset les variables "charge". Ce qui revient à supprimer 4 variables du dataset.

```{r}
mydata = subset(mydata, select = -c(Total.day.charge,Total.night.charge,Total.eve.charge,Total.intl.charge) )

train= mydata[id.train,]
test = mydata[id.test,]
attributes(test)$row.names = attributes(test0)$row.names

corrplot(cor(train[,c(2,3,6:(length(names(mydata))-1))]), method = "color", addCoef.col="grey", order = "AOE",tl.cex=0.75,tl.col="black",number.cex = 0.5)

```


```{r}
library(ggplot2)
ggplot(train, aes(x = Churn, fill=Customer.service.calls)) +
  geom_bar( ) +
  xlab("client ayant quitté") + ylab("Customer.service.calls") +
  ggtitle("Total de client ayant quitté")
```

```{r, message=FALSE}
library(dplyr)
library(usmap)
us.map=train
names(us.map)[names(us.map)=="State"]="state"
us.map = data.frame(us.map)

state.churn=us.map %>%
  group_by(state) %>%
  summarise(pct_perte.client = mean(Churn)*100)
```

```{r}
us.map = data.frame(us.map)

plot_usmap(regions="state", data=state.churn, values = "pct_perte.client", color="black")+
  scale_fill_continuous(low = "green", high = "red", name = "pct_perte.client (%)")+ 
  labs(title = "Perte clientèle États-Unis", subtitle = "Opérateur Orange télécom")+
  theme(legend.position = "right")

```
On constate que les états du Texas et New Jersey sont les états ayant perdus le plus de clientèle, avec un pourcentage de perte supérieur à 25%.\



## Régression logistique (validation croisé) --- a corriger la courbe roc ........

```{r}

train = train0
test = train0

set.seed(1234)

train$Churn[train$Churn == "False"] = 0
train$Churn[train$Churn == "True"] = 1
train$Churn = as.numeric(train$Churn)

test$Churn[test$Churn == "False"] = 0
test$Churn[test$Churn == "True"] = 1
test$Churn = as.numeric(test$Churn)


model1=glm(Churn~ ., family="binomial",data=train)
summary(model1)

#BIC  
round(BIC(model1), digit = 2)

#AIC
round(model1$aic, digit = 2)

library(ROCR)
prob.predict=predict.glm(model1,test,type="response")
cutoff=0.5
test.pred = rep(0, nrow(test))
test.pred[prob.predict > cutoff] = 1
M=table(test.pred, test$Churn,dnn=c("Prediction","Observation"))

a=M[1,1]
b=M[1,2]
c=M[2,1]
d=M[2,2]

# Sensibilité
Sensibilité = d/(b+d)

# Specificité
Specificité = a/(a+c)

# Taux d'erreures de classification (%)
((b+c)/(a+b+c+d))*100


pred=prediction(prob.predict,test$Churn)
perf=performance(pred,measure="tpr",x.measure="fpr")
auc.perf = performance(pred, measure = "auc")

plot(perf, main = "Courbe ROC")
abline(a=0,b=1)

```

## Arbre de classification élagé


```{r}

train = train0
test = train0

train$Churn[train$Churn == "False"] = 0
train$Churn[train$Churn == "True"] = 1
train$Churn = as.numeric(train$Churn)

test$Churn[test$Churn == "False"] = 0
test$Churn[test$Churn == "True"] = 1
test$Churn = as.numeric(test$Churn)

set.seed(400)

# Création de l'arbre : 
library(rpart.plot)

mytree = rpart(Churn~., data=train , method = "class")
cp_optimal=mytree$cptable[which.min(mytree$cptable[,4]),1]
mytree_optimal = prune(mytree,cp=cp_optimal)
prp(mytree_optimal,extra=1,roundint=FALSE, main = "Arbre avec élagage")


mytable=table(test$Churn, predict(mytree_optimal,test, type="class"))
names(dimnames(mytable))= c("Observed", "Predicted")
M = mytable

a=M[1,1]
b=M[1,2]
c=M[2,1]
d=M[2,2]


# Taux de mauvaises classifications
((b+c)/(a+b+c+d))*100


# Taux de faux positifs
round(((b+c)/(a+b+c+d))*100, digit = 2)

# Taux faux négatif 
round((1-(d/(b+d)))*100, digit = 2)

# Paramètre de complexité maximale
cp_optimal


# Boucle for

nb_boucle = 20

Taux_mauvaise_classificaiton=matrix(0,nb_boucle,1)
Taux_faux_positifs=matrix(0,nb_boucle,1)
Taux_faux_negatif=matrix(0,nb_boucle,1)
valeur_seed = matrix(0,nb_boucle,1)

par(mfrow=c(4,3))

for (i in 1:nb_boucle)
{
n=nrow(mydata)
set.seed(i*15231)
id.train=sample(1:n,size=nrow(train))
id.test=setdiff(1:n,id.train)

mydata.train= mydata[id.train,]
mydata.test = mydata[id.test,]

library(rpart.plot)
set.seed(i*15231)
valeur_seed[i]=i*15231

mytree = rpart(Churn~., data=mydata.train, method = "class")

cp_optimal=mytree$cptable[which.min(mytree$cptable[,4]),1]
mytree_optimal = prune(mytree,cp=cp_optimal)

#prp(mytree_optimal,extra=1,roundint=FALSE)

mytable=table(mydata.test$Churn, predict(mytree_optimal,mydata.test, type="class"))
names(dimnames(mytable))= c("Observed", "Predicted")
M = mytable

a=M[1,1]
b=M[1,2]
c=M[2,1]
d=M[2,2]

# Taux de mauvaises classifications
Taux_mauvaise_classificaiton[i]= ((b+c)/(a+b+c+d))
# Taux faux positifs
Taux_faux_positifs[i]= round((1-(a/(a+c))), digit = 2 ) 
# Taux faux négatif
Taux_faux_negatif[i] = round((1-(d/(b+d))), digit = 2)


}

par(mfrow=c(1,1))

plot(valeur_seed,Taux_mauvaise_classificaiton, type = "l", ylim= c(0,0.6), col = 3, ylab = "Taux", xlab = "Valeur de seed différent", main = "Variation du taux de mauvaises clasification,\n de faux positif et de faux négatif")
lines(valeur_seed,Taux_faux_positifs,col=1)
lines(valeur_seed,Taux_faux_negatif,col=2)
legend(90000, 0.6, legend=c("Faux positifs","Faux négatif","Mauvaises classifications"), col=1:3,lty=rep(1,3),title="Taux")

# Taux de faux positif 
## Maximum
round(max(Taux_faux_positifs), digit =2)

## Minimum
round(min(Taux_faux_positifs), digit =2)

# Taux de mauvaises classifications 
## Maximum
round(max(Taux_mauvaise_classificaiton), digit =2 )

## Minimum
round(min(Taux_mauvaise_classificaiton) , digit = 2)

# Taux faux négatif
## Maximum
round(max(Taux_faux_negatif), digit = 2)

## Minimum
round(min(Taux_faux_negatif), digit = 2)














```

## forêt aléatoire approche bagging


```{r}

train = train0
test = train0

train$Churn[train$Churn == "False"] = 0
train$Churn[train$Churn == "True"] = 1
train$Churn = as.numeric(train$Churn)

test$Churn[test$Churn == "False"] = 0
test$Churn[test$Churn == "True"] = 1
test$Churn = as.numeric(test$Churn)


library(randomForest)

mydata$Churn <- as.factor(mydata$Churn)

set.seed(1234)
n.arbre=seq(1,800,by=50)
erreur=NULL
for (i in n.arbre)
{
  rf=randomForest(Churn~.,data=mydata,ntree=i,mtry=length(colnames(mydata))-1)
  erreur=c(erreur,sum(rf$err.rate[,1])/rf$ntree)
}
plot(n.arbre, erreur,type="l")

rf=randomForest(Churn~.,data=mydata,ntree=600,mtry=length(colnames(mydata))-1)   
rf

importance(rf,type=1)

```

## Boosting

```{r}
library(randomForest)
library(adabag)

train = train0
test = train0

train$Churn[train$Churn == "False"] = 0
train$Churn[train$Churn == "True"] = 1
train$Churn = as.numeric(train$Churn)

test$Churn[test$Churn == "False"] = 0
test$Churn[test$Churn == "True"] = 1
test$Churn = as.numeric(test$Churn)

train$Churn=as.factor(train$Churn)
test$Churn=as.factor(test$Churn)

set.seed(1234)

# boosting with trees of depth 10
myboost=boosting(Churn~., data=train, mfinal = 100, coeflearn = 'Freund', control=rpart.control(maxdepth=10))
myboost$importance

pred=predict(myboost, newdata=test)

pred$error

M=pred$confusion


#mytable=table(myboost$class,mydata$Churn)   
# names(dimnames(mytable))= c("Predicted", "Observed")                       
# M = mytable
# M
# a=M[1,1]
# b=M[1,2]
# c=M[2,1]
# d=M[2,2]

# Taux de faux positifs
M[2,1]/(M[2,1]+M[1,1])

# Taux de faux négatifs
M[1,2]/(M[2,2]+M[1,2])


```


## SVM



# Résultats : présentation des résultats sous forme de tableaux et figures (ne mettez pas de sortie R)

# Conclusion/discussion : conclusion générale, limites de votre étude, qu’avez -vous appris ?


