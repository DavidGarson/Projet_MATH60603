---
# title: 'Projet '
# author: "Jean Guirguis (11290393) et David Gascon (xxxxxxx)"
# date: "xx/12/2020"
# output:
#   pdf_document:
#     toc: true
#   word_document: default
#   html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# Librairies
library(gridExtra)
library(grid)
library(ggplot2)
library(lattice)
```

# Introduction : présentation des objectifs de l’étude

L'objectif de cette étude est de faire une prédiction sur le désbonnemennt d'un client pour un service de télécommunication. Cette simulation a été fait à partir d'une base de données présent sur kaggle à l'adresse suivante : https://www.kaggle.com/mnassrib/telecom-churn-datasets?select=churn-bigml-80.csv. L'analyse a été effectué sur les client d'Orange Telecom aux États-Unis et plusieurs variables on été analysés tels que lieu géographique, le type de plan que le client possède, le nombre de minutes utilisé pour des appels durant le jour et le soir, etc. 

Ce rapport contient en premier lieu, une présentation détaillés de notre méthode d'analyse. Cette section contiendra d'abord une exploration détaillés des données possédés, un traitement et un nettoyage préparatoire des données. Puis, plusieurs méthode et stratégie de prédiction seront testés afin de déterminer le modèle le mieux adapté à notre échantillion d'utilisateurs. 

Une fois le modèle choisi, la deuxième section du rapport présentera les résultats du modèle de prédiction.  

... ... ... ... ... 




# Méthode : présentation du design de l’étude et des différents scénarios utilisés. Présentation de la méthode d’analyse en général.

## Exploration des données

### Présentation des varaibles
### Traitement et nettoyage préparatoire des données  










###################################


# Exploration des données

```{r}
# Importation des données

train=read.csv("data/churn-bigml-80.csv")
test=read.csv("data/churn-bigml-20.csv")
```


```{r}
summary(train)
```
## Réencodage des variables "State", "International.plan" et "Voice.mail.plan" en facteur. La variable d'intérêt est réencodée en variable logique, à savoir que les valeurs "vrai" sont codées "1" et les valeurs "faux" sont codées en 0
```{r}
### TRAIN ####
#transformation des variables "character" en "facteur"

train$State=as.factor(train$State)
train$International.plan=as.factor(train$International.plan)
train$Voice.mail.plan=as.factor(train$Voice.mail.plan)

#transformation variable d'intérêt en variable logique
train$Churn=as.logical(train$Churn)

### TEST ####
#transformation des variables "character" en "facteur"

test$State=as.factor(test$State)
test$International.plan=as.factor(test$International.plan)
test$Voice.mail.plan=as.factor(test$Voice.mail.plan)

#transformation variable d'intérêt en variable logique
test$Churn=as.logical(test$Churn)
```
## Étude descriptive des données

```{r}
# fonction 
analyse_table = function (nom,variable,nb_donne)
{
  table_temporaire= table(variable)
  table_temporaire = as.data.frame(table_temporaire)
  table_temporaire = data.frame(table_temporaire,pourcentage=round(table_temporaire[2]/nb_donne*100, digit =2))
  names(table_temporaire)[3] = "% Freq"
  names(table_temporaire)[1] = nom
  #table_temporaire = head(table_temporaire[order(-table_temporaire[3]),],3)
  table_temporaire = table_temporaire[order(-table_temporaire[3]),]
  return(table_temporaire)
}

analyse_table('State',train$State,nrow(train))
analyse_table('International.plan',train$International.plan,nrow(train))
analyse_table('Voice.mail.plan',train$Voice.mail.plan,nrow(train))
analyse_table('Churn',train$Churn,nrow(train))
analyse_table('Area.code',train$Area.code,nrow(train))
```


```{r}

par(mfrow=c(2,4))
for (i in 1:length(colnames(train)))
{
  if (i != 1 & i !=3  & i != 4 & i != 5 & i !=length(colnames(train)))
  {
    hist(train[,i], main = (colnames(train)[i] ),xlab = element_blank())
    Axis(side=1, labels=FALSE)
    #plot(train[,i], main = (colnames(train)[i] ))
  }
}
```


REMARQUE : Si on conserve les varialbes Customer.service.calls et total.intl,calls en variables numériques, il faudra surement prendre le log de ces variables car elles sont asymetriques à droite.!!

## Analyse descriptive des données 

```{r}
summary(train)
```

Le dataset d'entraînement ne contient aucune valeur manquante. il y a 15 variables continues, 3 variables catégorielles, et une variables binaires.

```{r}
round(mean(train$Churn),digits=2)
```
Le pourcentage de clients ayant quittés la compagnie est de 15%.\

```{r,include=FALSE}
library("plotly")
library("corrplot")
```

```{r}
corrplot(cor(train[,c(2,3,6:19)]), method = "color", addCoef.col="grey", order = "AOE",tl.cex=0.75,tl.col="black",number.cex = 0.5)
```
Les varaibles du dataset sont faiblement corrélées à l'exception des variables indiquant le nombre de muinutes consommés et les frais chargés associés, comme les varaibles : "Total.night charge" et "Total.night.minutes". Comme ces variables ont une corrélation parfaites, nous décidons de supprimer du dataset les variables "charge". Ce qui revient à supprimer 4 variables du dataset.

```{r}
library(ggplot2)
ggplot(train, aes(x = Churn, fill=Customer.service.calls)) +
  geom_bar( ) +
  xlab("client ayant quitté") + ylab("Customer.service.calls") +
  ggtitle("Total de client ayant quitté")

```

```{r, message=FALSE}
library(dplyr)
library(usmap)
us.map=train
names(us.map)[names(us.map)=="State"]="state"
us.map = data.frame(us.map)

state.churn=us.map %>%
  group_by(state) %>%
  summarise(pct_perte.client = mean(Churn)*100)
```

```{r}
us.map = data.frame(us.map)

plot_usmap(regions="state", data=state.churn, values = "pct_perte.client", color="black")+
  scale_fill_continuous(low = "green", high = "red", name = "pct_perte.client (%)")+ 
  labs(title = "Perte clientèle États-Unis", subtitle = "Opérateur Orange télécom")+
  theme(legend.position = "right")

```
On constate que les états du Texas et New Jersey sont les états ayant perdus le plus de clientèle, avec un pourcentage de perte supérieur à 25%.\



## Régression logistique (validation croisé)

### courbe de ROC et courbe lift
### Table de confusion 

#### Taux de mauvaise classisfication
#### Sensibilité
#### Spécificité
#### Taux de faux positifs 
#### Taux de faux négatif

## Arbre de classification (elagage VS non elague)

### elagage VS non elague VS CP optimale
### Table de confusion 

#### Taux de mauvaise classisfication
#### Sensibilité
#### Spécificité
#### Taux de faux positifs 
#### Taux de faux négatif

## forêt aléatoire 

### MSE et R2 et Importance

## Boagging

### MSE et R2 et Importance

## Boosting

### MSE et R2 et Importance

## SVM



# Résultats : présentation des résultats sous forme de tableaux et figures (ne mettez pas de sortie R)

# Conclusion/discussion : conclusion générale, limites de votre étude, qu’avez -vous appris ?


